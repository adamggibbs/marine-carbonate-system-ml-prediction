{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing_ship.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamggibbs/marine-carbonate-system-ml-prediction/blob/master/data_preprocessing_ship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXgoClbFFo7r"
      },
      "source": [
        "# SET UP ENVIRONMENT \n",
        "\n",
        "# mount google drive for data storage and access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#lib install\n",
        "!pip install PYCO2SYS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaFuIPPIF11R"
      },
      "source": [
        "# IMPORTS\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import PyCO2SYS as pyco2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94bRfLf-F4gA"
      },
      "source": [
        "# STORE DIRECTORY WHERE DATA IS STORED\n",
        "\n",
        "# this is an absolute path \n",
        "# and be sure to include trailing '/'\n",
        "data_dir = '/content/drive/MyDrive/Adam Gibbs/data/'\n",
        "ship_dir = data_dir + 'ship/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_bcWjp2GLHr"
      },
      "source": [
        "# Ship Data\n",
        "The following cells parse the ship data files. This section is split up into the following three code cells:\n",
        "\n",
        "1.   Display Raw Data\n",
        "2.   Parsing Function\n",
        "3.   Parse Data and Create Input Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y1GdGRdF5T1"
      },
      "source": [
        "# READ DATA INTO A PANDAS DATAFRAME TO DISPLAY\n",
        "\n",
        "print('Files in ship data folder:')\n",
        "display(os.listdir(ship_dir))\n",
        "\n",
        "dfs_ship= []\n",
        "for file in os.listdir(ship_dir):\n",
        "  df = pd.read_csv(ship_dir + file)\n",
        "  dfs_ship.append(df.dropna().reset_index(drop=True))\n",
        "\n",
        "print()\n",
        "print(\"There are {0} dataframes from {0} shipboard data files\".format(len(dfs_ship)))\n",
        "print(\"Adjust the index below to toggle display.\")\n",
        "print()\n",
        "\n",
        "display(dfs_ship[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbP1DmACF98U"
      },
      "source": [
        "# CREATE FUNCTION TO CREATE A NUMPY ARRAY OF INPUTS FROM\n",
        "# SHIP DATA FILE\n",
        "\n",
        "'''\n",
        "process_ship_file()\n",
        "  description:\n",
        "    This function reads in a data file in csv format and\n",
        "    creates a pandas dataframe from it. From there it loops through\n",
        "    and removes all bad data points according to the quality control\n",
        "    flags. It then takes the desired input parameters as sepcified on \n",
        "    line 74 and puts them into a numpy array.\n",
        "\n",
        "  args:\n",
        "    file: string that contains file name of dataset\n",
        "'''\n",
        "def process_ship_file(file):\n",
        "\n",
        "  # read in csv\n",
        "  df = pd.read_csv(file)\n",
        "  # take subset of data we care about\n",
        "  df = df[['DATE', 'LATITUDE', 'LONGITUDE', 'CTDPRS', 'CTDTMP', 'CTDSAL', \n",
        "           'CTDSAL_FLAG_W', 'OXYGEN', 'OXYGEN_FLAG_W', 'TCARBN', \n",
        "           'TCARBN_FLAG_W', 'PH_TOT', 'PH_TOT_FLAG_W']]\n",
        "  # drop any row with NaN values\n",
        "  df = df.dropna(axis=0, how='any').reset_index(drop=True)\n",
        "\n",
        "  # remove all bad data\n",
        "  # \"bad data\" has a QC flag that isn't 2\n",
        "  # do this for every parameter and its QC flags\n",
        "\n",
        "  # drop bad Salinity\n",
        "  index = 0\n",
        "  to_drop = []\n",
        "  for flag in df['CTDSAL_FLAG_W']:\n",
        "    if flag != 2:\n",
        "      to_drop.append(index)\n",
        "    index += 1\n",
        "  df = df.drop(to_drop).reset_index(drop=True)\n",
        "\n",
        "  # drop bad Oxygen\n",
        "  index = 0\n",
        "  to_drop = []\n",
        "  for flag in df['OXYGEN_FLAG_W']:\n",
        "    if flag != 2:\n",
        "      to_drop.append(index)\n",
        "    index += 1\n",
        "  df = df.drop(to_drop).reset_index(drop=True)\n",
        "\n",
        "  # drop bad Total Carbon\n",
        "  index = 0\n",
        "  to_drop = []\n",
        "  for flag in df['TCARBN_FLAG_W']:\n",
        "    if flag != 2:\n",
        "      to_drop.append(index)\n",
        "    index += 1\n",
        "  df = df.drop(to_drop).reset_index(drop=True)\n",
        "\n",
        "  # drop bad Total pH\n",
        "  index = 0\n",
        "  to_drop = []\n",
        "  for flag in df['PH_TOT_FLAG_W']:\n",
        "    if flag != 2:\n",
        "      to_drop.append(index)\n",
        "    index += 1\n",
        "  df = df.drop(to_drop).reset_index(drop=True)\n",
        "\n",
        "  # Convert shipboard pH to in situ pH\n",
        "\n",
        "  results = pyco2.sys(par1=df['PH_TOT'], par1_type=3,\n",
        "                    par2=df['TCARBN'], par2_type=2,\n",
        "                    temperature=25, pressure=0,\n",
        "                    temperature_out=df['CTDTMP'], pressure_out=df['CTDPRS'],\n",
        "                    salinity=df['CTDSAL'])\n",
        "\n",
        "  df['PH_TOT'] = results['pH_out']\n",
        "\n",
        "  # take subset of only parameters for inputs\n",
        "  # this array contains only \"good\" data points\n",
        "  inputs = df[['DATE', 'LATITUDE', 'LONGITUDE', 'CTDPRS', 'CTDTMP', 'CTDSAL', \n",
        "               'OXYGEN']]\n",
        "  outputs = df['PH_TOT']\n",
        "\n",
        "  # convert dataframe in numpy array\n",
        "  inputs = inputs.to_numpy()\n",
        "  outputs = outputs.to_numpy()\n",
        "\n",
        "  # return the array\n",
        "  return inputs, outputs\n",
        "\n",
        "\n",
        "'''\n",
        "process_ship_dir()\n",
        "  description:\n",
        "    This function takes a dir with shipboard data and processes\n",
        "    each file in that dir and creates input and output files. It\n",
        "    also has the option to save those input and output arrays to\n",
        "    either a .txt or a .csv file.\n",
        "\n",
        "  args:\n",
        "    file: string that contains file name of dataset\n",
        "    save_txt (default=False): boolean of whether to save a .txt\n",
        "    save_csv (default=False): boolean of whether to save a .csv\n",
        "'''\n",
        "def process_ship_dir(dir, save_txt=False, save_csv=False):\n",
        "  # list all data files in directory\n",
        "  print('Parsing the following files:')\n",
        "  print(os.listdir(dir))\n",
        "\n",
        "  # create an empty numpy array that will hold inputs\n",
        "  inputs = np.empty((0,7))\n",
        "  outputs = np.empty(0)\n",
        "\n",
        "  # loop through all data files and add them to input array\n",
        "  for file in os.listdir(dir):\n",
        "    input_array, output_array = process_ship_file(dir + file)\n",
        "    inputs = np.concatenate((inputs, input_array), axis=0)\n",
        "    outputs = np.concatenate((outputs, output_array), axis=0)\n",
        "\n",
        "  # if desired save arrays as .txt files\n",
        "  if save_txt or save_csv: \n",
        "    if save_txt:\n",
        "      input_header = 'DATE LATITUDE LONGITUDE CTDPRS CTDTMP CTDSAL OXYGEN'\n",
        "      np.savetxt(data_dir + 'ship_tpso_input.txt', inputs, \n",
        "                 fmt='%s', header=input_header)\n",
        "      output_header = 'TOT_PH'\n",
        "      np.savetxt(data_dir + 'ship_ph_output.txt', outputs, \n",
        "                 fmt='%s', header=output_header)\n",
        "    else:\n",
        "      input_header = 'DATE, LATITUDE, LONGITUDE, CTDPRS, CTDTMP, CTDSAL, OXYGEN'\n",
        "      np.savetxt(data_dir + 'ship_tpso_input.csv', inputs, \n",
        "                 fmt='%s', delimiter=\",\", header=input_header)\n",
        "      output_header = 'TOT_PH'\n",
        "      np.savetxt(data_dir + 'ship_ph_output.csv', outputs, \n",
        "                 fmt='%s', delimiter=\",\", header=output_header)\n",
        "\n",
        "  return inputs, outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogmttwINGBfp"
      },
      "source": [
        "# PARSE SHIP DATA AND CREATE INPUT ARRAY\n",
        "\n",
        "ship_inputs, ship_outputs = process_ship_dir(ship_dir, save_csv=True)\n",
        "\n",
        "# print input array and its dimensions\n",
        "print('Input array:')\n",
        "display(ship_inputs)\n",
        "\n",
        "print('Dimensions of input array:')\n",
        "display(ship_inputs.shape)\n",
        "\n",
        "# print output array and its dimensions\n",
        "print('Output array:')\n",
        "display(ship_outputs)\n",
        "\n",
        "print('Dimensions of output array:')\n",
        "display(ship_outputs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kotAvCGfJ05B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}